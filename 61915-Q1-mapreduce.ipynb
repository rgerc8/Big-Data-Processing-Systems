{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Question 1 - Daily and monthly statistics\n",
        "\n",
        "  For each sensor, compute the minimum, average and maximum values of the two sensor metrics. Produce results for each day.\n",
        "\n",
        " **Requirement**: Solve this question using MapReduce (MrJob) and Spark Core."
      ],
      "metadata": {
        "id": "vVUioJpsqZS-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeR7fAF6BTN9",
        "outputId": "be82cea8-0f8f-4f6c-e9c4-7e5d00b0ace7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#@title Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # Faz o mount da drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install MRJob and load dataset\n",
        "!pip install mrjob --quiet # Faz a instalação do MRJob\n",
        "!wget -q -O /etc/mrjob.conf https://raw.githubusercontent.com/smduarte/spbd-2223/main/lab2/mrjob.conf # Faz a configuração do MRJob\n",
        "# Faz o import dos dados\n",
        "!head -10000 /content/drive/MyDrive/projeto_spbd/sds011-2020-01-01.csv > files\n",
        "!head -10000 /content/drive/MyDrive/projeto_spbd/sds011-2020-01-02.csv >> files\n",
        "!head -10000 /content/drive/MyDrive/projeto_spbd/sds011-2020-01-03.csv >> files"
      ],
      "metadata": {
        "id": "WJoYvhszjCNL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Resolution using MRJob\n",
        "%%file min_max_mean.py\n",
        "\n",
        "from statistics import *\n",
        "from mrjob.job import MRJob, MRStep\n",
        "\n",
        "class MRMinMaxMean(MRJob):\n",
        "  # Mapper\n",
        "  def mapper(self, _, line):\n",
        "    sensor, sistema, latit, longit, period, p1, p2 = line.split(';') # Faz o split de cada linha do ficheiro csv, dividindo-o em 6 campos\n",
        "    dia = period[0:10] # Retira o dia do period\n",
        "    p1 = float(p1) # Passa a métrica p1 para float\n",
        "    p2 = float(p2) # Passa a métrica p2 para float\n",
        "    valores = (p1,p2) # Junta as duas métricas, p1 e p2, como value\n",
        "    k = (sensor, dia) # Cria uma tuple (sensor, dia)\n",
        "    yield k, valores\n",
        "  # Reducer\n",
        "  def reducer(self, k, valores):\n",
        "    vp1 = [] # Cria uma lista vazia para inserir os valores de p1\n",
        "    vp2 = [] # Cria uma lista vazia para inserir os valores de p2\n",
        "    for p1, p2 in valores:\n",
        "      vp1.append(p1) # Cada valor de p1 é adicionado à lista criada\n",
        "      vp2.append(p2) # Cada valor de p2 é adicionado à lista criada\n",
        "    yield k, (max(vp1), min(vp1), mean(vp1), max(vp2), min(vp2), mean(vp2)) # Para cada sensor, é impresso os valores máximo, mínimo e médio de cada lista (vp1 e vp2)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    MRMinMaxMean.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPbGMm0GaYVo",
        "outputId": "f42b38a0-520b-41bb-e17e-a8e05900e1a7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting min_max_mean.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf results\n",
        "!python -m min_max_mean  --output-dir results --cleanup NONE '/content/files'\n",
        "!head results/*\n",
        "# Impressão dos resultados"
      ],
      "metadata": {
        "id": "HTWFHks1vB7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f036f860-9c33-4191-f51d-f414bfe402fc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using configs in /etc/mrjob.conf\n",
            "No configs specified for inline runner\n",
            "Running step 1 of 1...\n",
            "Creating temp directory /tmp/min_max_mean.root.20221221.171621.595709\n",
            "job output is in results\n",
            "==> results/part-00000 <==\n",
            "[\"1000\", \"2020-01-01\"]\t[341.53, 297.97, 319.75, 275.53, 239.2, 257.365]\n",
            "[\"1000\", \"2020-01-02\"]\t[12.13, 10.53, 11.186666666666667, 9.0, 7.37, 8.223333333333333]\n",
            "[\"1000\", \"2020-01-03\"]\t[18.0, 15.0, 16.5, 13.73, 12.4, 13.065000000000001]\n",
            "[\"10009\", \"2020-01-01\"]\t[75.3, 69.03, 72.16499999999999, 44.77, 44.53, 44.650000000000006]\n",
            "[\"10009\", \"2020-01-02\"]\t[21.53, 21.0, 21.265, 12.33, 12.3, 12.315000000000001]\n",
            "[\"10009\", \"2020-01-03\"]\t[14.17, 12.23, 13.2, 8.4, 7.4, 7.9]\n",
            "[\"10011\", \"2020-01-01\"]\t[112.47, 105.67, 109.07, 56.9, 52.9, 54.9]\n",
            "[\"10011\", \"2020-01-02\"]\t[35.6, 35.37, 35.485, 16.77, 16.67, 16.72]\n",
            "[\"10011\", \"2020-01-03\"]\t[24.37, 23.23, 23.8, 12.1, 11.33, 11.715]\n",
            "[\"10029\", \"2020-01-01\"]\t[5.57, 5.57, 5.57, 5.1, 5.1, 5.1]\n",
            "\n",
            "==> results/part-00001 <==\n",
            "[\"18455\", \"2020-01-02\"]\t[154.18, 105.7, 129.94, 35.38, 33.05, 34.215]\n",
            "[\"18455\", \"2020-01-03\"]\t[75.85, 74.37, 75.11, 31.42, 31.23, 31.325000000000003]\n",
            "[\"18457\", \"2020-01-01\"]\t[635.47, 635.47, 635.47, 568.03, 568.03, 568.03]\n",
            "[\"18457\", \"2020-01-02\"]\t[40.6, 38.47, 39.535, 32.8, 32.37, 32.584999999999994]\n",
            "[\"18457\", \"2020-01-03\"]\t[5.6, 5.6, 5.6, 5.1, 5.1, 5.1]\n",
            "[\"18459\", \"2020-01-01\"]\t[280.87, 273.0, 276.935, 124.97, 121.63, 123.3]\n",
            "[\"18459\", \"2020-01-02\"]\t[58.23, 58.23, 58.23, 22.33, 22.33, 22.33]\n",
            "[\"18459\", \"2020-01-03\"]\t[5.6, 4.47, 5.035, 2.9, 2.7, 2.8]\n",
            "[\"18461\", \"2020-01-01\"]\t[114.7, 114.7, 114.7, 51.83, 51.83, 51.83]\n",
            "[\"18461\", \"2020-01-02\"]\t[56.13, 56.13, 56.13, 25.83, 25.83, 25.83]\n",
            "\n",
            "==> results/part-00002 <==\n",
            "[\"27243\", \"2020-01-01\"]\t[14.82, 14.82, 14.82, 3.6, 3.6, 3.6]\n",
            "[\"27243\", \"2020-01-02\"]\t[19.27, 11.73, 15.5, 6.65, 6.07, 6.36]\n",
            "[\"27243\", \"2020-01-03\"]\t[36.42, 36.42, 36.42, 10.2, 10.2, 10.2]\n",
            "[\"27245\", \"2020-01-01\"]\t[75.43, 75.43, 75.43, 41.28, 41.28, 41.28]\n",
            "[\"27245\", \"2020-01-02\"]\t[59.75, 59.75, 59.75, 27.58, 27.58, 27.58]\n",
            "[\"27245\", \"2020-01-03\"]\t[49.95, 49.95, 49.95, 21.33, 21.33, 21.33]\n",
            "[\"27251\", \"2020-01-01\"]\t[265.15, 227.9, 240.57999999999998, 185.57, 156.2, 165.93125]\n",
            "[\"27251\", \"2020-01-02\"]\t[64.95, 59.03, 62.36, 44.83, 40.67, 42.10375]\n",
            "[\"27259\", \"2020-01-01\"]\t[174.0, 163.62, 168.81, 74.93, 74.22, 74.575]\n",
            "[\"27259\", \"2020-01-02\"]\t[31.95, 28.87, 30.41, 10.13, 9.68, 9.905000000000001]\n",
            "\n",
            "==> results/part-00003 <==\n",
            "[\"36681\", \"2020-01-01\"]\t[55.77, 44.17, 49.97, 17.83, 16.07, 16.95]\n",
            "[\"36681\", \"2020-01-02\"]\t[37.5, 37.5, 37.5, 14.27, 14.27, 14.27]\n",
            "[\"36681\", \"2020-01-03\"]\t[107.97, 98.2, 103.08500000000001, 41.07, 40.5, 40.785]\n",
            "[\"36695\", \"2020-01-01\"]\t[119.72, 63.8, 91.75999999999999, 53.33, 28.92, 41.125]\n",
            "[\"36695\", \"2020-01-02\"]\t[46.8, 42.33, 44.565, 17.83, 17.02, 17.424999999999997]\n",
            "[\"36695\", \"2020-01-03\"]\t[42.17, 41.55, 41.86, 18.15, 17.52, 17.835]\n",
            "[\"36705\", \"2020-01-01\"]\t[39.0, 35.55, 37.275, 20.02, 18.05, 19.035]\n",
            "[\"36705\", \"2020-01-02\"]\t[45.6, 36.67, 41.135000000000005, 16.9, 14.87, 15.884999999999998]\n",
            "[\"36705\", \"2020-01-03\"]\t[51.13, 41.85, 46.49, 21.48, 21.17, 21.325000000000003]\n",
            "[\"36707\", \"2020-01-01\"]\t[54.5, 40.2, 47.35, 23.17, 19.58, 21.375]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Pyspark\n",
        "!pip install --quiet pyspark # Faz a instalação do Pyspark"
      ],
      "metadata": {
        "id": "AP0EWG2chyZx"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Resolution using Spark Core\n",
        "import pyspark\n",
        "from operator import *\n",
        "\n",
        "sc = pyspark.SparkContext('local[*]') # Cria o SparkContext, em local mode\n",
        "\n",
        "try:\n",
        "  lines = sc.textFile('/content/files').map( lambda line: line.strip() ) # Faz o carregamento dos dados e o strip de cada linha do ficheiro\n",
        "  \n",
        "  sensors = lines.map( lambda line: line.split(';')) # Faz o split de cada linha do ficheiro csv, dividindo-o em 6 campos\n",
        "  sensors1 = sensors.filter( lambda values: len(values) > 0) # Faz o filtro para reter, apenas, as linhas que são superiores a zero, ou seja, não nulas\n",
        "  sensors2 = sensors1.map( lambda values: ((values[0],values[4][0:10]), (float(values[5]), float(values[6])))) # Faz o map, sendo o número do sensor a key e a tuple (p1, p2), em float, a value\n",
        "  sensors3 = sensors2.map( lambda kv : (kv[0], (1, kv[1][0], kv[1][0], kv[1][0], kv[1][1], kv[1][1], kv[1][1]))) # Faz o map, sendo o número de do sensor a key e a tuple (1, p1, p1, p1, p2, p2, p2)\n",
        "  sensors4 = sensors3.reduceByKey( lambda a, b : (a[0] + b[0], a[1] + b[1], max(a[2],b[2]), min(a[3],b[3]), a[4] + b[4], max(a[5],b[5]), min(a[6],b[6])) ) # Faz o reduceByKey, criando uma value correspondente a: (1+1, p1+p1, max(p1,p1), min(p1,p1), p2+p2, max(p2,p2), min(p2,p2)). Soma 1+1, p1+p1 e p2+p2, de cada linha, e preserva o min e max para cada valor de p1 e p2. \n",
        "  sensors5 = sensors4.map( lambda kv : ( kv[0] , (kv[1][2] , kv[1][3] , kv[1][1] / kv[1][0] , kv[1][5] , kv[1][6], kv[1][4] / kv[1][0]))) # Faz o map, sendo o número do sensor a key e a tuple (max p1, min p1, mean p1, max p2, min p2, mean p2)\n",
        "  sensors6 = sensors5.sortByKey() # Faz o sortByKey, por ordem crescente do número do sensor\n",
        "       \n",
        "  for sensor in sensors6.take(20): \n",
        "    print(sensor)\n",
        "  # Faz o print dos 20 primeiros valores\n",
        "  sc.stop()\n",
        "except Exception as e: \n",
        "  print(e)\n",
        "  sc.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXHOzWvblBZA",
        "outputId": "0893cad1-69c4-4627-9f34-510828e914dd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(('1000', '2020-01-01'), (341.53, 297.97, 319.75, 275.53, 239.2, 257.365))\n",
            "(('1000', '2020-01-02'), (12.13, 10.53, 11.186666666666667, 9.0, 7.37, 8.223333333333334))\n",
            "(('1000', '2020-01-03'), (18.0, 15.0, 16.5, 13.73, 12.4, 13.065000000000001))\n",
            "(('10009', '2020-01-01'), (75.3, 69.03, 72.16499999999999, 44.77, 44.53, 44.650000000000006))\n",
            "(('10009', '2020-01-02'), (21.53, 21.0, 21.265, 12.33, 12.3, 12.315000000000001))\n",
            "(('10009', '2020-01-03'), (14.17, 12.23, 13.2, 8.4, 7.4, 7.9))\n",
            "(('10011', '2020-01-01'), (112.47, 105.67, 109.07, 56.9, 52.9, 54.9))\n",
            "(('10011', '2020-01-02'), (35.6, 35.37, 35.485, 16.77, 16.67, 16.72))\n",
            "(('10011', '2020-01-03'), (24.37, 23.23, 23.8, 12.1, 11.33, 11.715))\n",
            "(('10029', '2020-01-01'), (5.57, 5.57, 5.57, 5.1, 5.1, 5.1))\n",
            "(('10029', '2020-01-02'), (0.98, 0.6, 0.79, 0.98, 0.6, 0.79))\n",
            "(('10029', '2020-01-03'), (0.7, 0.43, 0.565, 0.7, 0.43, 0.565))\n",
            "(('1004', '2020-01-01'), (637.47, 478.33, 557.9, 455.2, 331.97, 393.58500000000004))\n",
            "(('1004', '2020-01-02'), (57.1, 56.43, 56.765, 29.93, 28.97, 29.45))\n",
            "(('1004', '2020-01-03'), (23.8, 23.8, 23.8, 15.2, 15.2, 15.2))\n",
            "(('10041', '2020-01-01'), (126.47, 126.47, 126.47, 57.27, 57.27, 57.27))\n",
            "(('10041', '2020-01-02'), (70.6, 66.8, 68.69999999999999, 31.1, 30.4, 30.75))\n",
            "(('10041', '2020-01-03'), (63.83, 63.83, 63.83, 19.1, 19.1, 19.1))\n",
            "(('10056', '2020-01-01'), (157.0, 119.73, 137.91, 102.93, 76.5, 89.84333333333332))\n",
            "(('10056', '2020-01-02'), (12.03, 9.47, 10.423333333333334, 7.07, 6.93, 7.010000000000001))\n"
          ]
        }
      ]
    }
  ]
}