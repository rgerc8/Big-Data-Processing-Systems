{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM6P5ye2ZYQu"
      },
      "source": [
        "### Question 2 - Top 3 Cities\n",
        "\n",
        "  For each country, compute the top 3 cities with best air quality and the top 3 cities with poorest air quality, updated weekly, i.e., averaged over a week (7 days).\n",
        "\n",
        " **Requirement**: Solve this question using Spark Core, Spark Dataframes and Spark SQL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5lTR4xHZl-M",
        "outputId": "33772913-e780-4183-c998-d4b41980abcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#@title Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive') # Faz o mount da drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VONcpBPeZPYi",
        "outputId": "1b3f4eda-077d-4ca6-e3de-ae4831c128fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 281.4 MB 42 kB/s \n",
            "\u001b[K     |████████████████████████████████| 199 kB 52.6 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "#@title Install Pyspark\n",
        "!pip install --quiet pyspark # Faz a instalação do Pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gsSUYaWlOmwM"
      },
      "outputs": [],
      "source": [
        "#@title Dataset\n",
        "!head -10000 /content/drive/MyDrive/projeto_spbd/sds011-2020-01-0*.csv > files\n",
        "!head -10000 /content/drive/MyDrive/projeto_spbd/sds011-2020-01-1*.csv >> files\n",
        "!head -10000 /content/drive/MyDrive/projeto_spbd/sds011-2020-01-2*.csv >> files\n",
        "!head -10000 /content/drive/MyDrive/projeto_spbd/sds011-2020-01-3*.csv >> files\n",
        "!head -10000 /content/drive/MyDrive/projeto_spbd/sds011-2020-02-0*.csv >> files\n",
        "!head -10000 /content/drive/MyDrive/projeto_spbd/sds011-2020-02-1*.csv >> files\n",
        "!head -10000 /content/drive/MyDrive/projeto_spbd/sds011-2020-02-2*.csv >> files\n",
        "!head -10000 /content/drive/MyDrive/projeto_spbd/sds011-2020-03-0*.csv >> files\n",
        "!head -10000 /content/drive/MyDrive/projeto_spbd/sds011-2020-03-1*.csv >> files\n",
        "!head -10000 /content/drive/MyDrive/projeto_spbd/sds011-2020-03-2*.csv >> files\n",
        "!head -10000 /content/drive/MyDrive/projeto_spbd/sds011-2020-03-3*.csv >> files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6c1asmRR-iM",
        "outputId": "d072fdd8-cc75-4f33-d102-c3077679f433"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------- TOP 3 CITIES WITH POOREST AIR QUALITY ----------\n",
            "+-------+-----------------+----+------------------+----+\n",
            "|country|             city|week|            metric|rank|\n",
            "+-------+-----------------+----+------------------+----+\n",
            "| France|           Luitré|   1|2097.0089213053384|   1|\n",
            "| France|        Gallardon|   1| 886.9899520874023|   2|\n",
            "| France|          Tullins|   1|340.68750071525574|   3|\n",
            "| France|           Luitré|   2| 2999.800048828125|   1|\n",
            "| France|        Fonsorbes|   2|160.16167163848877|   2|\n",
            "| France|          Crusnes|   2| 144.1007126399449|   3|\n",
            "| France|           Luitré|   3| 2999.800048828125|   1|\n",
            "| France|         Péchabou|   3|238.21727440573952|   2|\n",
            "| France|           Anglet|   3|103.99766685962678|   3|\n",
            "| France|           Luitré|   4|  759.272006225586|   1|\n",
            "| France|Serémange-Erzange|   4|276.13205500210034|   2|\n",
            "| France|            Passy|   4|180.86461580716647|   3|\n",
            "| France|        Tinténiac|   5| 339.0488944186105|   1|\n",
            "| France|    Bois-Colombes|   5|234.99750518798828|   2|\n",
            "| France|           Luitré|   5|172.39142663138253|   3|\n",
            "| France|           Luitré|   6| 2999.800048828125|   1|\n",
            "| France|            Passy|   6|171.98727763782847|   2|\n",
            "| France|         Péchabou|   6| 88.60999743143718|   3|\n",
            "| France|           Luitré|   7| 2999.800048828125|   1|\n",
            "| France|           Jardin|   7|136.05181902105159|   2|\n",
            "+-------+-----------------+----+------------------+----+\n",
            "only showing top 20 rows\n",
            "\n",
            "---------- TOP 3 CITIES WITH BEST AIR QUALITY ----------\n",
            "+-------+-----------------+----+-------------------+----+\n",
            "|country|             city|week|             metric|rank|\n",
            "+-------+-----------------+----+-------------------+----+\n",
            "| France|       Arnouville|   1| 0.3333333416117562|   1|\n",
            "| France|Sargé-lès-le-Mans|   1| 0.9644444319936964|   2|\n",
            "| France|            Brest|   1| 1.6174999475479126|   3|\n",
            "| France|       Arnouville|   2|0.11454545604911717|   1|\n",
            "| France|Sargé-lès-le-Mans|   2| 1.0930769397662237|   2|\n",
            "| France|            Brest|   2| 2.6324999928474426|   3|\n",
            "| France|       Arnouville|   3|0.27166666959722835|   1|\n",
            "| France|            Brest|   3| 0.5500000268220901|   2|\n",
            "| France|Sargé-lès-le-Mans|   3| 1.1764285830514771|   3|\n",
            "| France|       Arnouville|   4|  0.613333351082272|   1|\n",
            "| France|Sargé-lès-le-Mans|   4| 1.2546153847987835|   2|\n",
            "| France|           Figeac|   4|  2.631666660308838|   3|\n",
            "| France|       Arnouville|   5|0.16363636607473547|   1|\n",
            "| France|         Huningue|   5|0.30444445709387463|   2|\n",
            "| France|         Mulhouse|   5| 0.8216666703422865|   3|\n",
            "| France|       Arnouville|   6| 0.2800000041723251|   1|\n",
            "| France|         Huningue|   6| 0.5949999950826168|   2|\n",
            "| France|         Mulhouse|   6| 0.9800000339746475|   3|\n",
            "| France|       Arnouville|   7|0.13333333532015482|   1|\n",
            "| France|          Tournus|   7| 1.5666666626930237|   2|\n",
            "+-------+-----------------+----+-------------------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#@title Resolution using Spark SQL\n",
        "import math\n",
        "import pyspark\n",
        "import json\n",
        "import string\n",
        "from pyspark.sql import *\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from datetime import datetime\n",
        "from operator import *\n",
        "from pyspark import pandas\n",
        "\n",
        "spark = SparkSession.builder.master('local[*]').appName('/content/files').getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "\n",
        "try :\n",
        "    custom_schema = StructType([StructField(\"sen_id\", StringType(), True),StructField(\"file_id\", StringType(), True),StructField(\"lat\", FloatType(), True),StructField(\"lon\", FloatType(), True),StructField(\"timestamp\", TimestampType(), True),StructField(\"p1\", FloatType(), True),StructField(\"p2\", FloatType(), True),])\n",
        "    # É criado um schema\n",
        "    main_data = spark.read.schema(custom_schema).load('/content/files', sep=';', header=False, format=\"csv\") # O dataset principal é atribuído ao schema criado\n",
        "    aux_data=spark.read.json('/content/drive/MyDrive/projeto_spbd/sensors_all.json') # Carregamento do dataset secundário (JSON)\n",
        "    main_data.createOrReplaceTempView('maindata') # Criada uma Temporary View para o dataset principal\n",
        "    aux_data.createOrReplaceTempView('auxdata') # Criada uma Temporary View para o dataset secundário\n",
        "    # Join data\n",
        "    joint_data=spark.sql('SELECT sen_id, country, city, timestamp, p1, p2 FROM maindata INNER JOIN auxdata ON sensor_id=sen_id') # É feito o INNER JOIN entre os dois datasets, pelo sensor_id\n",
        "    joint_data.createOrReplaceTempView('full_data') # Criada uma Temporary View para o dataset inteiro, já depois de ser feito o INNER JOINT\n",
        "    query1=spark.sql('SELECT country, city, WEEKOFYEAR(timestamp) AS week, AVG(p1+p2) AS metric FROM full_data GROUP BY country, city, WEEKOFYEAR(timestamp) ORDER BY week, metric DESC')\n",
        "    # O query1 faz o SELECT do country, city, semana do ano, média da soma dos valores de p1 e p2.\n",
        "    # Faz o GROUP BY por country, city e week, à semelhança do que foi feito no Spark DataFrame.\n",
        "    # Faz o ORDER BY week e metric, de forma descendente.\n",
        "    query1.createOrReplaceTempView('full_data_2') # Criada uma Temporary View, com os resultados do query1\n",
        "    # Top_cities\n",
        "    top_cities=spark.sql('SELECT * FROM (SELECT country, city, week, metric, RANK() OVER (PARTITION BY country, week ORDER BY metric DESC) AS rank FROM full_data_2) AS a WHERE rank <=3')\n",
        "    # O top_cities faz o SELECT do country, city, semana, metric e rank.\n",
        "    # O rank é feito pelos valores da metric, tendo em conta a partição país e semana. Ou seja, para cada country e week, são apresentados os valores da metric (de forma descendente), bem como a cidade a que corresponde.\n",
        "    # São apresentados apenas os valores para os rankings menores ou iguais a 3, ou seja, os 3 maiores valores para cada conjunto country/semana.\n",
        "    top_cities.createOrReplaceTempView('full_data_3') # Criada uma Temporary View com os resultados do top_cities\n",
        "    # Tail_cities\n",
        "    tail_cities=spark.sql('SELECT * FROM (SELECT country, city, week, metric, RANK() OVER (PARTITION BY country, week ORDER BY metric ASC) AS rank FROM full_data_2) AS a WHERE rank <=3')\n",
        "    # O tail_cities faz o SELECT do country, city, semana, metric e rank.\n",
        "    # O rank é feito pelos valores da metric, tendo em conta a partição país e semana. Ou seja, para cada country e week, são apresentados os valores da metric (de forma ascendente), bem como a cidade a que corresponde.\n",
        "    # São apresentados apenas os valores para os rankings menores ou iguais a 3, ou seja, os 3 menores valores para cada conjunto country/semana.\n",
        "    tail_cities.createOrReplaceTempView('full_data_4') # Criada uma Temporary View com os resultados do tail_cities\n",
        "    print(\"---------- TOP 3 CITIES WITH POOREST AIR QUALITY ----------\")\n",
        "    top_cities.show() # Apresenta os valores do top_cities\n",
        "    print(\"---------- TOP 3 CITIES WITH BEST AIR QUALITY ----------\")\n",
        "    tail_cities.show() # Apresenta os valores do tail_cities\n",
        "except Exception as err:\n",
        "    print(err)\n",
        "    sc.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
